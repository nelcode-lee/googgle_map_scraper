# Google Maps Business Scraper

A comprehensive Google Maps business scraper with multiple scraping methods for maximum coverage and data quality. This project combines Google Places API, web scraping with Selenium, and intelligent data processing to capture business information across various industries.

## üöÄ Features

### Multiple Scraping Methods
- **Enhanced Places API**: Nearby search, text search, autocomplete, and multi-term search
- **Web Scraping**: Direct Selenium-based scraping to bypass API limitations
- **Comprehensive Multi-Method**: Combines all approaches for maximum coverage
- **Known Business Search**: Targets specific businesses you know exist

### Industry Support
- **CPCS/CSCS Training**: Construction and plant operator training centers
- **Restaurants & Food**: Cafes, restaurants, diners, and food establishments
- **Technology**: IT companies, software firms, and tech services
- **Custom Industries**: Easily configurable for any business type

### Advanced Features
- **Intelligent Deduplication**: Removes duplicate businesses across methods
- **Data Quality Scoring**: Rates business data completeness
- **Industry-Specific Tables**: Creates separate database tables per industry
- **Radius-Based Search**: Configurable search radius in miles
- **Real-Time Progress**: Live updates during scraping process
- **Companies House Integration**: Business verification and additional discovery

## üìä Results

### Recent Test Results (CPCS Training in Manchester):
- **Total businesses found**: 189
- **Method breakdown**:
  - Web general search: 5 businesses
  - Web multi-term search: 39 businesses
  - Known business search: 13 businesses
  - Alternative locations: 24 businesses

### Sample Businesses Found:
- Manchester Plant Training Ltd
- Greater Manchester Construction Training Ltd
- Cheshire Training Solutions
- Platinum Training Services
- Smiths Training - Manchester Openshaw
- CV Training - Forklift Training
- Pearson Professional Centre - Manchester
- GEM Compliance Training | Manchester
- And many more...

## üõ†Ô∏è Installation

### Prerequisites
- Python 3.13+
- Google Places API key
- PostgreSQL database (Neon DB recommended)
- Chrome browser (for web scraping)

### Setup
1. **Clone the repository**:
   ```bash
   git clone https://github.com/nelcode-lee/googgle_map_scraper.git
   cd googgle_map_scraper
   ```

2. **Create virtual environment**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment**:
   ```bash
   cp .env.example .env
   # Edit .env with your API keys and database credentials
   ```

5. **Set up database**:
   ```bash
   python setup.py
   ```

## üöÄ Usage

### Web Interface (Recommended)
```bash
python simple_app.py
```
Open your browser to `http://localhost:8080`

### Command Line Usage

#### Comprehensive Scraper (Best Results)
```bash
python final_comprehensive_scraper.py
```

#### Web Scraper Only
```bash
python simple_web_scraper.py
```

#### Enhanced API Scraper
```bash
python enhanced_simple_scraper.py
```

#### Search for Specific Business
```bash
python search_operator_skills_hub.py
```

### Programmatic Usage
```python
from final_comprehensive_scraper import FinalComprehensiveScraper

scraper = FinalComprehensiveScraper()
result = await scraper.scrape_and_save_comprehensive(
    industry="CPCS training",
    location="Manchester, UK",
    radius_miles=25
)
print(f"Found {result['found']} businesses")
```

## üìÅ Project Structure

```
google_maps_scraper/
‚îú‚îÄ‚îÄ üìÑ Core Scrapers
‚îÇ   ‚îú‚îÄ‚îÄ enhanced_scraper.py          # Enhanced Places API scraper
‚îÇ   ‚îú‚îÄ‚îÄ simple_web_scraper.py        # Web scraping with Selenium
‚îÇ   ‚îú‚îÄ‚îÄ final_comprehensive_scraper.py # Multi-method comprehensive scraper
‚îÇ   ‚îî‚îÄ‚îÄ places_api_scraper.py        # Basic Places API scraper
‚îú‚îÄ‚îÄ üìÑ Web Interface
‚îÇ   ‚îú‚îÄ‚îÄ simple_app.py                # Flask web application
‚îÇ   ‚îú‚îÄ‚îÄ app.py                       # Alternative Flask app
‚îÇ   ‚îî‚îÄ‚îÄ templates/index.html         # Web interface template
‚îú‚îÄ‚îÄ üìÑ Database & Processing
‚îÇ   ‚îú‚îÄ‚îÄ database.py                  # Database management
‚îÇ   ‚îú‚îÄ‚îÄ data_processor.py            # Data cleaning and deduplication
‚îÇ   ‚îî‚îÄ‚îÄ companies_house.py           # Companies House API integration
‚îú‚îÄ‚îÄ üìÑ Utilities
‚îÇ   ‚îú‚îÄ‚îÄ config.py                    # Configuration settings
‚îÇ   ‚îú‚îÄ‚îÄ utils.py                     # Utility functions
‚îÇ   ‚îî‚îÄ‚îÄ examples.py                  # Usage examples
‚îú‚îÄ‚îÄ üìÑ Documentation
‚îÇ   ‚îú‚îÄ‚îÄ README.md                    # This file
‚îÇ   ‚îú‚îÄ‚îÄ SCRAPING_METHODS_SUMMARY.md # Detailed scraping methods
‚îÇ   ‚îú‚îÄ‚îÄ API_SETUP_GUIDE.md          # API setup instructions
‚îÇ   ‚îî‚îÄ‚îÄ WEB_INTERFACE.md            # Web interface documentation
‚îî‚îÄ‚îÄ üìÑ Scripts
    ‚îú‚îÄ‚îÄ run.sh                       # Convenience script
    ‚îú‚îÄ‚îÄ setup.py                     # Setup script
    ‚îî‚îÄ‚îÄ clear_database.py            # Database clearing utility
```

## üîß Configuration

### Environment Variables (.env)
```env
# Google Places API
GOOGLE_PLACES_API_KEY=your_api_key_here

# Database Configuration
DATABASE_URL=postgresql://user:password@host:port/database

# Companies House API (Optional)
COMPANIES_HOUSE_API_KEY=your_api_key_here
```

### Search Term Customization
Edit `final_comprehensive_scraper.py` to customize search terms for different industries:

```python
def _generate_search_terms(self, industry: str) -> List[str]:
    if 'cpcs' in industry.lower():
        return [
            'CPCS training', 'CSCS training', 'construction training',
            'plant training', 'operator training', 'forklift training',
            # Add more terms as needed
        ]
```

## üìà Performance

### Scraping Speed
- **Places API**: ~60 businesses per minute
- **Web Scraping**: ~20-30 businesses per minute
- **Comprehensive**: ~40-50 businesses per minute (combined)

### Coverage Improvement
- **Standard API**: ~60 businesses
- **Enhanced Methods**: ~189 businesses (3x improvement)
- **Comprehensive**: ~200+ businesses (3.3x improvement)

## üõ°Ô∏è Error Handling

- **API Rate Limiting**: Automatic backoff and retry
- **Network Issues**: Robust error handling and recovery
- **Data Validation**: Comprehensive data cleaning and validation
- **Duplicate Prevention**: Intelligent deduplication across methods
- **Logging**: Detailed logging for debugging and monitoring

## üìä Database Schema

### Main Businesses Table
```sql
CREATE TABLE businesses (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    address TEXT,
    phone VARCHAR(50),
    website TEXT,
    email VARCHAR(255),
    google_rating DECIMAL(3,2),
    google_place_id VARCHAR(255),
    industry VARCHAR(100),
    search_term VARCHAR(100),
    search_location VARCHAR(100),
    postcode VARCHAR(20),
    opening_hours JSONB,
    place_id VARCHAR(255),
    types TEXT,
    geometry TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### Industry-Specific Tables
Each industry search creates a dedicated table (e.g., `industry_cpcs_training`) with the same schema for organized data storage.

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- Google Places API for business data
- Selenium for web scraping capabilities
- Companies House API for business verification
- The open-source community for various Python libraries

## üìû Support

For questions, issues, or contributions, please:
- Open an issue on GitHub
- Check the documentation in the `/docs` folder
- Review the examples in `examples.py`

---

**Note**: This scraper is designed for legitimate business research purposes. Please respect Google's Terms of Service and implement appropriate rate limiting for production use.